{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog = pd.read_csv(\"naver_blog.csv\", index_col=0)[\"Content\"]\n",
    "stopwords = pd.read_csv(\"stopwords.csv\")[\"Stopwords\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preprocess strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "for i in range(len(blog)):\n",
    "    pos = okt.pos(blog[i])\n",
    "    text1 = list(filter(lambda x: (x[1] == 'Noun') |(x[1] == 'Adjective'), pos))    \n",
    "    text2 = list(filter(lambda x: x[0] not in stopwords, text1))\n",
    "    text3 = list(filter(lambda x: len(x[0]) > 1, text2))\n",
    "    line = \"\"\n",
    "    for word in text3:\n",
    "        line += word[0] + \" \"\n",
    "    blog[i] = line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(blog)\n",
    "lda_model = LatentDirichletAllocation(n_components = 3,  learning_method='online', random_state=777, max_iter=1)\n",
    "lda_top = lda_model.fit_transform(X)\n",
    "\n",
    "terms = vectorizer.get_feature_names() \n",
    "topics = []\n",
    "for idx, topic in enumerate(lda_model.components_):\n",
    "    for i in topic.argsort()[:-5 -1:-1]:\n",
    "            topics.append(terms[i])\n",
    "topics = pd.unique(topics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find related words and define link dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weight(df):\n",
    "    indi = 2\n",
    "    while len(df[df[\"weight\"] > indi]) > 120:\n",
    "        indi += 1\n",
    "    return indi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "big_txt = []\n",
    "blog = blog.apply(lambda x: x.split())\n",
    "for i in range(len(blog)):\n",
    "    txt = pd.Series(blog[i], dtype=\"object\")\n",
    "    c_idx = txt[txt.isin(topics)].index.tolist()\n",
    "    idx_mat = []\n",
    "    for j in range(-3,4):\n",
    "        temp = list(map(lambda x: x+j, c_idx))\n",
    "        idx_mat.append(temp)\n",
    "    idx_mat_t = np.transpose(idx_mat)\n",
    "    \n",
    "    num = [0,1,2,4,5,6]\n",
    "    temp_val = []\n",
    "    for k in num:\n",
    "        idx_df = pd.DataFrame(idx_mat_t)\n",
    "        for l in range(len(idx_df)):\n",
    "            temp_val.append(idx_df.iloc[l, [k,3]].values)\n",
    "    val.append(temp_val)\n",
    "big_txt = []\n",
    "for i in range(len(val)):\n",
    "    for j in range(len(val[i])):\n",
    "        f = val[i][j][0]\n",
    "        l = val[i][j][1]\n",
    "        if (f < 0) or (f >= len(blog[i]))  :\n",
    "            pass\n",
    "        else:\n",
    "            big_txt.append([blog[i][f], blog[i][l]])\n",
    "            \n",
    "df = pd.DataFrame(big_txt, columns = [\"from\", \"to\"])\n",
    "df[\"xx\"] = df[\"from\"] + \" \" + df[\"to\"]\n",
    "counter = df.groupby(\"xx\").count().reset_index().drop('to', axis=1).rename(columns = {\"from\" : \"weight\"})\n",
    "links = pd.merge(df, counter, on = \"xx\")\n",
    "links = links.drop_duplicates()\n",
    "indi = find_weight(links)\n",
    "links = links[(links[\"weight\"] > indi) & (links[\"weight\"] < 1000)]\n",
    "links = links.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define node dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.unique(links[[\"from\", \"to\"]].values.flatten())\n",
    "vv = links.iloc[:,1].values\n",
    "val = np.repeat(min(links[\"weight\"]), len(nodes))\n",
    "matin = []\n",
    "for i in range(len(vv)):\n",
    "    temp = np.where(nodes == vv[i])[0]\n",
    "    matin = np.concatenate([matin, temp])\n",
    "matin = pd.unique(matin)\n",
    "matin = list(map(lambda x: int(x), matin))\n",
    "val[matin] = links.iloc[matin, 3]\n",
    "\n",
    "nodes = pd.DataFrame(nodes, nodes).reset_index()\n",
    "nodes[\"value\"] = val\n",
    "nodes = nodes.rename(columns = {\"index\" : \"id\", 0:\"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = pd.read_csv(\"color.csv\")[\"good_color\"].values\n",
    "color_idx = list(map(lambda x: int(x), np.linspace(start=0, stop=len(color)-1, num=len(nodes))))\n",
    "nodes[\"color\"] = color[color_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Using networkx, plot a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "plt.figure(figsize=(25,25))\n",
    "\n",
    "#1 create networkx graph object\n",
    "G = nx.Graph()\n",
    "\n",
    "#2 Based on the counts of node dataframe, create circles as 'nodes' in network graph\n",
    "\n",
    "for index, row in nodes.iterrows():\n",
    "    G.add_node(row['label'], nodesize=row['value'], node_color = row[\"color\"])\n",
    "\n",
    "#3 Create circles as 'relations\" in network graph \n",
    "for index, row in links.iterrows():\n",
    "    G.add_weighted_edges_from([(row['from'], row['to'], row['weight'])])\n",
    "\n",
    "#4 Set parameters related with graph design\n",
    "pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "sizes = [G.nodes[node]['nodesize']*250 for node in G]\n",
    "nx.draw(G, pos=pos, node_size=sizes, node_color = nodes[\"color\"])\n",
    "\n",
    "nx.draw_networkx_labels(G, pos=pos, font_family=\"AppleGothic\", font_size=25)\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
